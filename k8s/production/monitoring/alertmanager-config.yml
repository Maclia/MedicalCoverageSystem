apiVersion: v1
kind: ConfigMap
metadata:
  name: alertmanager-config
  namespace: medical-coverage
  labels:
    app: alertmanager
    environment: production
data:
  alertmanager.yml: |
    global:
      smtp_smarthost: 'smtp.production.email-service.com:587'
      smtp_from: 'alerts@medical-coverage.com'
      smtp_auth_username: 'smtp_user_prod'
      smtp_auth_password: 'smtp_prod_password123'
      slack_api_url: 'https://hooks.slack.com/services/YOUR/SLACK/WEBHOOK'
      wechat_api_url: 'https://qyapi.weixin.qq.com/cgi-bin/webhook/send?key=YOUR_WECHAT_KEY'

    templates:
    - '/etc/alertmanager/templates/*.tmpl'

    route:
      group_by: ['alertname', 'cluster', 'service']
      group_wait: 10s
      group_interval: 10s
      repeat_interval: 1h
      receiver: 'default-receiver'
      routes:
      - match:
          severity: critical
        receiver: 'critical-alerts'
        group_wait: 5s
        repeat_interval: 15m
        routes:
        - match:
            alertname: ServiceDown
          receiver: 'service-down-alerts'
          repeat_interval: 5m
        - match:
            alertname: PostgreSQLDown
          receiver: 'database-alerts'
          repeat_interval: 5m
        - match:
            alertname: RedisDown
          receiver: 'database-alerts'
          repeat_interval: 5m

      - match:
          severity: warning
        receiver: 'warning-alerts'
        group_wait: 30s
        repeat_interval: 2h

      - match:
          severity: info
        receiver: 'info-alerts'
        group_wait: 1m
        repeat_interval: 4h

      # Business logic specific routes
      - match:
          alertname: HighAuthenticationFailures
        receiver: 'security-alerts'
        repeat_interval: 30m

      - match:
          alertname: ClaimProcessingDelay
        receiver: 'business-alerts'
        repeat_interval: 1h

      - match:
          alertname: BillingErrors
        receiver: 'business-alerts'
        repeat_interval: 1h

      # Infrastructure specific routes
      - match:
          alertname: PodCrashLooping
        receiver: 'infrastructure-alerts'
        repeat_interval: 15m

      - match:
          alertname: DiskSpaceLow
        receiver: 'infrastructure-alerts'
        repeat_interval: 30m

    receivers:
    - name: 'default-receiver'
      email_configs:
      - to: 'devops@medical-coverage.com'
        subject: '[Medical Coverage] {{ .GroupLabels.alertname }} - {{ .Status | toUpper }}'
        body: |
          {{ range .Alerts }}
          Alert: {{ .Annotations.summary }}
          Description: {{ .Annotations.description }}
          Labels: {{ range .Labels.SortedPairs }}{{ .Name }}={{ .Value }} {{ end }}
          {{ end }}
      slack_configs:
      - channel: '#alerts'
        title: 'Medical Coverage Alert'
        text: |
          {{ range .Alerts }}
          *Alert:* {{ .Annotations.summary }}
          *Description:* {{ .Annotations.description }}
          *Labels:* {{ range .Labels.SortedPairs }}{{ .Name }}={{ .Value }} {{ end }}
          {{ end }}

    - name: 'critical-alerts'
      email_configs:
      - to: 'oncall@medical-coverage.com,devops@medical-coverage.com'
        subject: '[CRITICAL] Medical Coverage Production Alert - {{ .GroupLabels.alertname }}'
        body: |
          CRITICAL ALERT - IMMEDIATE ATTENTION REQUIRED

          {{ range .Alerts }}
          Alert: {{ .Annotations.summary }}
          Description: {{ .Annotations.description }}
          Severity: {{ .Labels.severity }}
          Service: {{ .Labels.job }}
          Instance: {{ .Labels.instance }}
          Started: {{ .StartsAt.Format "2006-01-02 15:04:05" }}

          Runbook: https://runbooks.medical-coverage.com/{{ .Labels.alertname }}
          Dashboard: https://grafana.medical-coverage.com/d/medical-coverage
          {{ end }}
      slack_configs:
      - channel: '#critical-alerts'
        title: 'üö® CRITICAL ALERT - Medical Coverage'
        color: 'danger'
        text: |
          {{ range .Alerts }}
          *Alert:* {{ .Annotations.summary }}
          *Description:* {{ .Annotations.description }}
          *Service:* {{ .Labels.job }}
          *Instance:* {{ .Labels.instance }}
          *Runbook:* https://runbooks.medical-coverage.com/{{ .Labels.alertname }}
          {{ end }}
      pagerduty_configs:
      - service_key: 'YOUR_PAGERDUTY_SERVICE_KEY'
        description: '{{ range .Alerts }}{{ .Annotations.summary }}{{ end }}'
        details:
          firing: '{{ .Alerts.Firing | len }}'
          resolved: '{{ .Alerts.Resolved | len }}'
          cluster: 'medical-coverage-production'

    - name: 'service-down-alerts'
      email_configs:
      - to: 'oncall@medical-coverage.com,devops@medical-coverage.com,product@medical-coverage.com'
        subject: '[SERVICE DOWN] Medical Coverage - {{ .GroupLabels.service }} is UNAVAILABLE'
        body: |
          SERVICE DOWN - IMMEDIATE ATTENTION REQUIRED

          The following service is currently down:
          {{ range .Alerts }}
          Service: {{ .Labels.service }}
          Description: {{ .Annotations.description }}
          Started: {{ .StartsAt.Format "2006-01-02 15:04:05" }}
          Dashboard: https://grafana.medical-coverage.com/d/service-overview
          {{ end }}
      slack_configs:
      - channel: '#service-outages'
        title: 'üî• SERVICE DOWN - Medical Coverage'
        color: 'danger'
        text: |
          {{ range .Alerts }}
          *Service Down:* {{ .Labels.service }}
          *Description:* {{ .Annotations.description }}
          *Started:* {{ .StartsAt.Format "2006-01-02 15:04:05" }}
          *Impact:* Users may be unable to access the system
          {{ end }}

    - name: 'database-alerts'
      email_configs:
      - to: 'dba@medical-coverage.com,devops@medical-coverage.com'
        subject: '[DATABASE] Medical Coverage - {{ .GroupLabels.alertname }}'
        body: |
          DATABASE ALERT - ATTENTION REQUIRED

          {{ range .Alerts }}
          Alert: {{ .Annotations.summary }}
          Description: {{ .Annotations.description }}
          Database: {{ .Labels.job }}
          Started: {{ .StartsAt.Format "2006-01-02 15:04:05" }}
          {{ end }}

    - name: 'warning-alerts'
      email_configs:
      - to: 'devops@medical-coverage.com'
        subject: '[WARNING] Medical Coverage - {{ .GroupLabels.alertname }}'
        body: |
          Warning Alert - Monitor Closely

          {{ range .Alerts }}
          Alert: {{ .Annotations.summary }}
          Description: {{ .Annotations.description }}
          Service: {{ .Labels.job }}
          Started: {{ .StartsAt.Format "2006-01-02 15:04:05" }}
          {{ end }}
      slack_configs:
      - channel: '#warnings'
        title: '‚ö†Ô∏è WARNING - Medical Coverage'
        color: 'warning'
        text: |
          {{ range .Alerts }}
          *Alert:* {{ .Annotations.summary }}
          *Description:* {{ .Annotations.description }}
          *Service:* {{ .Labels.job }}
          {{ end }}

    - name: 'info-alerts'
      slack_configs:
      - channel: '#info'
        title: '‚ÑπÔ∏è INFO - Medical Coverage'
        color: 'good'
        text: |
          {{ range .Alerts }}
          *Alert:* {{ .Annotations.summary }}
          *Description:* {{ .Annotations.description }}
          {{ end }}

    - name: 'security-alerts'
      email_configs:
      - to: 'security@medical-coverage.com,devops@medical-coverage.com'
        subject: '[SECURITY] Medical Coverage - {{ .GroupLabels.alertname }}'
        body: |
          SECURITY ALERT - INVESTIGATE IMMEDIATELY

          {{ range .Alerts }}
          Alert: {{ .Annotations.summary }}
          Description: {{ .Annotations.description }}
          Severity: {{ .Labels.severity }}
          Started: {{ .StartsAt.Format "2006-01-02 15:04:05" }}
          {{ end }}
      slack_configs:
      - channel: '#security'
        title: 'üîí SECURITY ALERT - Medical Coverage'
        color: 'danger'
        text: |
          {{ range .Alerts }}
          *Security Alert:* {{ .Annotations.summary }}
          *Description:* {{ .Annotations.description }}
          *Started:* {{ .StartsAt.Format "2006-01-02 15:04:05" }}
          {{ end }}

    - name: 'business-alerts'
      email_configs:
      - to: 'business@medical-coverage.com,product@medical-coverage.com,devops@medical-coverage.com'
        subject: '[BUSINESS] Medical Coverage - {{ .GroupLabels.alertname }}'
        body: |
          BUSINESS ALERT - CUSTOMER IMPACT

          {{ range .Alerts }}
          Alert: {{ .Annotations.summary }}
          Description: {{ .Annotations.description }}
          Impact: This may affect customer experience
          Started: {{ .StartsAt.Format "2006-01-02 15:04:05" }}
          {{ end }}
      slack_configs:
      - channel: '#business-alerts'
        title: 'üíº BUSINESS ALERT - Medical Coverage'
        color: 'warning'
        text: |
          {{ range .Alerts }}
          *Business Alert:* {{ .Annotations.summary }}
          *Description:* {{ .Annotations.description }}
          *Impact:* Customer experience may be affected
          {{ end }}

    - name: 'infrastructure-alerts'
      email_configs:
      - to: 'devops@medical-coverage.com,infrastructure@medical-coverage.com'
        subject: '[INFRASTRUCTURE] Medical Coverage - {{ .GroupLabels.alertname }}'
        body: |
          INFRASTRUCTURE ALERT - SYSTEM HEALTH

          {{ range .Alerts }}
          Alert: {{ .Annotations.summary }}
          Description: {{ .Annotations.description }}
          Component: {{ .Labels.job }}
          Started: {{ .StartsAt.Format "2006-01-02 15:04:05" }}
          {{ end }}
      slack_configs:
      - channel: '#infrastructure'
        title: 'üèóÔ∏è INFRASTRUCTURE ALERT - Medical Coverage'
        color: 'warning'
        text: |
          {{ range .Alerts }}
          *Infrastructure Alert:* {{ .Annotations.summary }}
          *Description:* {{ .Annotations.description }}
          *Component:* {{ .Labels.job }}
          {{ end }}

    inhibit_rules:
    # Inhibit info alerts when warning alerts are firing for the same service
    - source_match:
        severity: 'warning'
      target_match:
        severity: 'info'
      equal: ['service', 'alertname']

    # Inhibit warning alerts when critical alerts are firing for the same service
    - source_match:
        severity: 'critical'
      target_match:
        severity: 'warning'
      equal: ['service', 'alertname']

    # Inhibit all alerts if the entire service is down
    - source_match:
        alertname: 'ServiceDown'
      target_match_re:
        service: '{{ .Labels.service }}.*'